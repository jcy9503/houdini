{"body": [{"indent": 0, "text": ["Labs AV Meshing"], "type": "title", "extent": [0, 20], "level": 0}, {"indent": 0, "type": "summary", "extent": [139, 230], "text": ["  Creates a dense geometric surface representation of the scene using Alicevision. "]}, {"indent": 0, "type": "para", "extent": [230, 428], "text": ["The objective of this step is to create a dense geometric surface representation of the scene. The output of this node is a high-poly mesh, which can be used for any further processing in Houdini."]}, {"body": [{"body": [{"indent": 4, "type": "para", "extent": [433, 643], "text": ["You can provide a bounding box around the output pointcloud of the ", {"text": ["AV Depth Map"], "type": "code"}, " node to isolate regions of the reconstructed scene to refine. Simply feed in a box (no other shape) into the second input."]}], "indent": 0, "role": "item", "extent": [428, 433], "container": true, "type": "tip"}], "container": true, "role": "item_group", "type": "tip_group"}, {"body": [{"body": [{"body": [{"body": [{"indent": 8, "type": "para", "extent": [680, 729], "text": ["Start the cooking process for this step."]}], "indent": 4, "text": ["Cook"], "role": "item", "extent": [670, 680], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [746, 849], "text": ["This toggle controls if the node should automatically recook if any dependencies have changed."]}], "indent": 4, "text": ["Manual Mode"], "role": "item", "extent": [729, 746], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [862, 1020], "text": ["This toggle controls if the status of the current node should be printed to the console. This is useful for getting a quick overview of the progress."]}], "indent": 4, "text": ["Use Log"], "role": "item", "extent": [849, 862], "container": true, "type": "parameters_item"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 4, "level": 2, "text": ["Main"], "extent": [655, 670], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "extent": [1060, 1115], "text": ["Max input points loaded from depth map images."]}], "indent": 4, "text": ["Max Input Points"], "role": "item", "extent": [1038, 1060], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1131, 1187], "text": ["Max points at the end of the depth maps fusion."]}], "indent": 4, "text": ["Max Points"], "role": "item", "extent": [1115, 1131], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1213, 1243], "text": ["Max points per voxel."]}], "indent": 4, "text": ["Max Points per Voxel"], "role": "item", "extent": [1187, 1213], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1257, 1490], "text": ["The step used to load depth values from depth maps is computed from maxInputPts. Here we define the minimal value for this step, so on small datasets we will not spend too much time at the beginning loading all depth values."]}], "indent": 4, "text": ["Min Step"], "role": "item", "extent": [1243, 1257], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1509, 1572], "text": ["Whether to colorize output dense point cloud and mesh."]}], "indent": 4, "text": ["Vertex Colors"], "role": "item", "extent": [1490, 1509], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1590, 1619], "text": ["Enable Partitioning."]}], "indent": 4, "text": ["Partitioning"], "role": "item", "extent": [1572, 1590], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1636, 1667], "text": ["Enable Repartitioning."]}], "indent": 4, "text": ["Repartition"], "role": "item", "extent": [1619, 1636], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1685, 1706], "text": ["AngleFactor."]}], "indent": 4, "text": ["Angle Factor"], "role": "item", "extent": [1667, 1685], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1722, 1742], "text": ["Sim Factor."]}], "indent": 4, "text": ["Sim Factor"], "role": "item", "extent": [1706, 1722], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1769, 1800], "text": ["pixSizeMarginInitCoef."]}], "indent": 4, "text": ["pixSizeMarginInitCoef"], "role": "item", "extent": [1742, 1769], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1828, 1860], "text": ["pixSizeMarginFinalCoef."]}], "indent": 4, "text": ["pixSizeMarginFinalCoef"], "role": "item", "extent": [1800, 1828], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1882, 1908], "text": ["voteMarginFactor."]}], "indent": 4, "text": ["voteMarginFactor"], "role": "item", "extent": [1860, 1882], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1936, 1968], "text": ["contributeMarginFactor."]}], "indent": 4, "text": ["contributeMarginFactor"], "role": "item", "extent": [1908, 1936], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [1993, 2022], "text": ["simGaussianSizeInit."]}], "indent": 4, "text": ["simGaussianSizeInit"], "role": "item", "extent": [1968, 1993], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2043, 2068], "text": ["simGaussianSize."]}], "indent": 4, "text": ["simGaussianSize"], "role": "item", "extent": [2022, 2043], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2091, 2118], "text": ["minAngleThreshold."]}], "indent": 4, "text": ["minAngleThreshold"], "role": "item", "extent": [2068, 2091], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2135, 2232], "text": ["Refine depth map fusion with the new pixels size defined by angle and similarity scores."]}], "indent": 4, "text": ["Refine Fuse"], "role": "item", "extent": [2118, 2135], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2261, 2305], "text": ["Estimate the 3d space from the SfM."]}], "indent": 4, "text": ["Estimate Space From SfM"], "role": "item", "extent": [2232, 2261], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2352, 2417], "text": ["Minimum number of observations for SfM space estimation."]}], "indent": 4, "text": ["Min Observations For SfM Space Estimation"], "role": "item", "extent": [2305, 2352], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2470, 2543], "text": ["Minimum angle between two observations for SfM space estimation."]}], "indent": 4, "text": ["Min Observations Angle For SfM Space Estimation"], "role": "item", "extent": [2417, 2470], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2587, 2639], "text": ["Add SfM Landmarks to the dense point cloud."]}], "indent": 4, "text": ["Add Landmarks To The Dense Point Cloud"], "role": "item", "extent": [2543, 2587], "container": true, "type": "parameters_item"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 4, "level": 2, "text": ["Meshing"], "extent": [1020, 1038], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "extent": [2696, 2848], "text": ["Remove all large triangles. We consider a triangle as large if one edge is bigger than N times the average edge length. Put zero to disable it."]}], "indent": 4, "text": ["Filter Large Triangles Factor"], "role": "item", "extent": [2661, 2696], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2880, 2937], "text": ["Keep only the largest connected triangles group."]}], "indent": 4, "text": ["Keep Only the Largest Mesh"], "role": "item", "extent": [2848, 2880], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [2960, 3000], "text": ["Number of smoothing iterations."]}], "indent": 4, "text": ["Num of Iterations"], "role": "item", "extent": [2937, 2960], "container": true, "type": "parameters_item"}, {"body": [{"indent": 8, "type": "para", "extent": [3012, 3029], "text": ["Lambda."]}], "indent": 4, "text": ["Lambda"], "role": "item", "extent": [3000, 3012], "container": true, "type": "parameters_item"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 4, "level": 2, "text": ["Mesh Filter"], "extent": [2639, 2661], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "extent": [3068, 3244], "text": ["The environment used for launching the AliceVision utilities commandline. Note that this is a python expression and should be modified only through \"Edit Expression\"."]}], "indent": 4, "text": ["Environment"], "role": "item", "extent": [3051, 3068], "container": true, "type": "parameters_item"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 4, "level": 2, "text": ["Environment"], "extent": [3029, 3051], "container": true, "type": "h", "id": null}], "indent": 0, "level": 1, "text": "Parameters", "role": "section", "extent": [643, 655], "container": true, "type": "parameters_section", "id": "parameters"}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "extent": [3266, 3314], "text": ["This should get the output of AV Depth Map."]}], "indent": 0, "text": ["AV Depth Map"], "extent": [3252, 3266], "container": true, "type": "dt"}, {"body": [{"indent": 4, "type": "para", "extent": [3328, 3491], "text": ["This can optionally receive a bounding box to refine the region that should be reconstructed. This is only allowed to be a transformed box, and nothing else."]}], "indent": 0, "text": ["Bounding BOX"], "extent": [3314, 3328], "container": true, "type": "dt"}], "container": true, "type": "dt_group"}], "indent": 0, "level": 1, "text": "Inputs", "role": "section", "extent": [3244, 3252], "container": true, "type": "inputs_section", "id": "inputs"}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "extent": [3514, 3578], "text": ["This plugs into AV Texturing, and holds the generated mesh."]}], "indent": 0, "text": ["AV Depth Map"], "extent": [3500, 3514], "container": true, "type": "dt"}, {"body": [{"indent": 4, "type": "para", "extent": [3590, 3647], "text": ["This is the pointcloud generated by the meshing step."]}], "indent": 0, "text": ["Pointcloud"], "extent": [3578, 3590], "container": true, "type": "dt"}], "container": true, "type": "dt_group"}], "indent": 0, "level": 1, "text": "Outputs", "role": "section", "extent": [3491, 3500], "container": true, "type": "outputs_section", "id": "outputs"}], "summary": ["  Creates a dense geometric surface representation of the scene using Alicevision. "], "type": "root", "attrs": {"version": "5.0", "tags": "sidefxlabs,  photogrammetry", "namespace": "labs", "internal": "labs::av_meshing::5.0", "context": "sop", "type": "node", "icon": "alicevision.png"}, "title": ["Labs AV Meshing"]}